{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from transformers import SeamlessM4Tv2Model, AutoProcessor\n",
    "\n",
    "from src.tokenize import AggregatedTokenizer\n",
    "from src.generate import AggregatedGenerator\n",
    "from src.evaluate import SimilarityChecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\") \n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/nllb-200-3.3B\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/nllb-200-3.3B\").to(device)\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"facebook/seamless-m4t-v2-large\")\n",
    "model2 = SeamlessM4Tv2Model.from_pretrained(\"facebook/seamless-m4t-v2-large\").to(device)\n",
    "\n",
    "tokenizer3 = AutoTokenizer.from_pretrained(\"google/madlad400-3b-mt\")\n",
    "model3 = AutoModelForSeq2SeqLM.from_pretrained(\"google/madlad400-3b-mt\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seamless_tokenizer_postprocessing(decoder_inputs):\n",
    "    input_ids_data = decoder_inputs['input_ids']\n",
    "    decoder_inputs['input_ids'] = input_ids_data[(input_ids_data != 0) & (input_ids_data != 3)].unsqueeze(0) \n",
    "\n",
    "\n",
    "agg_tokenizer = AggregatedTokenizer(\n",
    "    tokenizers=[\n",
    "        tokenizer, \n",
    "        processor.tokenizer,\n",
    "        tokenizer3,\n",
    "    ],\n",
    "    tokenization_kwargs=[\n",
    "        dict(),\n",
    "        dict(src_lang=\"eng\", tgt_lang=\"rus\"),\n",
    "        dict(),\n",
    "    ],\n",
    "    decoder_tokenization_postprocessing=[\n",
    "        None,\n",
    "        seamless_tokenizer_postprocessing,\n",
    "        None\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_generator = AggregatedGenerator(\n",
    "    models=[\n",
    "        model, \n",
    "        model2,\n",
    "        model3,\n",
    "    ],\n",
    "    generation_kwargs=[\n",
    "        dict(),\n",
    "        dict(generate_speech=False),\n",
    "        dict(),\n",
    "\n",
    "    ],\n",
    "    agg_tokenizer=agg_tokenizer,\n",
    "    decoder_prompts = [\n",
    "        \"rus_Cyrl\",\n",
    "        \"__rus__\",\n",
    "        None,\n",
    "    ],\n",
    "    encoder_prompts = [\n",
    "        None,\n",
    "        None,\n",
    "        \"<2ru>\"\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_checker = SimilarityChecker(score_names=['bertscore'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_text = \"\"\"\n",
    "Virgin Australia, the trading name of Virgin Australia Airlines Pty Ltd, \n",
    "is an Australian-based airline. It is the largest airline by fleet size \n",
    "to use the Virgin brand. It commenced services on 31 August 2000 as \n",
    "Virgin Blue, with two aircraft on a single route. It suddenly found \n",
    "itself as a major airline in Australia's domestic market after the \n",
    "collapse of Ansett Australia in September 2001. The airline has since \n",
    "grown to directly serve 32 cities in Australia, from hubs in Brisbane, \n",
    "Melbourne and Sydney.\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_single_translations = agg_generator.generate_all_single(encoder_input_text, device=device)\n",
    "all_single_translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_tranlation = agg_generator.generate_agg(encoder_input_text, num_beams=3, max_new_tokens=256, device=device)\n",
    "ensemble_tranlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bertscore': {'precision': 0.7491934100786845,\n",
       "  'recall': 0.6914637486139933,\n",
       "  'f1': 0.7189777493476868}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_checker.check_similarity(text=all_single_translations)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
